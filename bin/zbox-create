#!/usr/bin/python3

import grp
import pwd
import shutil
import time
from pathlib import Path
from textwrap import dedent

# noinspection PyUnresolvedReferences
from bin_util import *
from zbox.config import Configuration
from zbox.env import *
from zbox.filelock import FileLock
from zbox.util import *


# Note: deliberately not using os.path.join for joining paths throughout the code,
# since it only works on Linux like systems where path separator will always be "/"
# and explicitly forcing the same.
#
# Configuration files should be in $HOME/.config/zbox or /etc/zbox.

@typechecked
def main() -> None:
    args = parse_args()
    box_name, docker_cmd = process_args(args)
    print_color(f"Creating zbox container named '{box_name}'", fg=fgcolor.purple)
    env = Environ()
    conf = Configuration(args, env, box_name)
    support_list = conf.get_config_file("supported.list")
    distro = args.distribution
    # check that the distribution is in supported.list
    with open(support_list, "r", encoding="utf-8") as supp_file:
        if distro not in supp_file.read().splitlines():
            sys.exit(f"Distribution '{distro}' not supported in {support_list}")

    # setup entrypoint and related scripts to share with the container on a mount point
    setup_zbox_scripts(distro, conf)

    # the configuration file used to build the docker/podman command-line
    config_file = args.configuration
    if not os.access(config_file, os.R_OK):
        config_file = conf.get_config_file(config_file)
    docker_full_args = [docker_cmd, "run", "-itd", f"--name={box_name}"]
    # process the configuration file before any actions to ensure it is in proper shape
    shared_root = process_sections(config_file, distro, env, conf, docker_full_args)
    current_user = getpass.getuser()

    # The sequence for container creation and run is thus:
    # 1) First start a basic container with the smallest upstream distro image (important to
    #    save space when 'base.shared_root' is true) with "entrypoint-base.sh" as the entrypoint
    #    script giving user/group arguments to be same as the user as on the host machine.
    # 2) Next do a docker/podman commit and save the stopped container as local image which
    #    will be used henceforth. The main point of doing #1 is to ensure that a sudo enabled
    #    user is available which matches the current host user so that "--userns" option
    #    will not try to remap the image that can substantially increase the size of image.
    #    Either way, the user created by "--userns" in the container does not have sudo
    #    permissions, so we temporarily need to run such a container as root user in any case.
    #    Hence, step 1 uses a cleaner and better option that also creates separate
    #    container-specific images that can be enhanced with more container-specific stuff
    #    later if required. Also change the USER and WORKDIR of the commit to point to the
    #    user added in step 1).
    # 3) Start up the saved image of step 2 and run the distro specific entrypoint script
    #    that will do basic configuration and package installation (e.g. git/neovim/... on arch)
    #    followed by the generic "entrypoint.sh" script which will create the configuration
    #    file links (from [configs] section), install required apps (from [apps] section),
    #    followed by invoking the startup scripts from the [startup] section.
    # 4) The container is now ready to use so 'zbox-shell' will only do a docker/podman exec
    #    of /bin/bash to open a shell.
    # 5) Mounts and environment variables are set up for step 3 which are automatically also
    #    available in step 4, and hence no special setup is required in step 4.
    #
    # If 'base.shared_root' is true, the above sequence has the following changes:
    # 1) First acquire a file/process lock so that no other container creation can interfere.
    # 2) Once the lock has been acquired, check if the shared container image already exists.
    #    If it does exist, then skip to step 7.
    # 3) If not, then start the basic container like in step 1) of previous sequence.
    # 4) Like step 2) of the previous sequence, commit the container but with a temporary name.
    # 5) Unlike step 3) of the previous sequence, do a temporary restart of the previous
    #    committed image with "--userns=keep-id" option, and then copy the shared root
    #    directories to the shared mount point. This copying cannot be done in step 4) above
    #    because the file permissions are different with and without the --userns option.
    # 6) Stop the container and commit the image again with the final shared image name.
    #    Delete the previous temporary image. Release the file lock acquired in step 1).
    # 7) Now start the shared image like in step 3) of the previous sequence but with the
    #    additional root directory mounts that were copied in step 5 above.
    # Finally, continue with step 4) onwards of previous sequence.

    # handle the shared_root case: acquire file lock and check if shared container image exists
    shared_root_dirs = ""
    if shared_root:
        os.makedirs(os.path.dirname(conf.shared_root_host_dir), exist_ok=True)
        with FileLock(f"{conf.shared_root_host_dir}-image.lock"):
            image_exists = subprocess.run([docker_cmd, "inspect", "--type=image",
                                           "--format={{.Id}}", conf.box_image(True)],
                                          stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            # if image already exists, then skip the subsequent steps
            if image_exists.returncode != 0:
                # run the "base" container with appropriate arguments for the current user to
                # the 'entrypoint-base.sh' script to create the user and group in the container
                shared_root_dirs = run_base_container(current_user, distro, docker_cmd, conf)
                # commit the stopped container with a temporary name, then remove the container
                tmp_image = f"{conf.box_image(False)}__zbox_tmp"
                commit_container(current_user, docker_cmd, tmp_image, conf)
                # start a container using the temporary image with "--userns" option to make
                # a copy of the container root directories to the shared location
                run_shared_copy_container(distro, docker_cmd, tmp_image, shared_root_dirs, conf)
                # finally commit this container with the name of the shared image
                commit_container(current_user, docker_cmd, conf.box_image(True), conf)
                remove_image(docker_cmd, tmp_image)
            else:
                _, shared_root_dirs, _ = read_distribution_config(distro, conf)
    else:
        # run the "base" container with appropriate arguments for the current user to the
        # 'entrypoint-base.sh' script to create the user and group in the container
        run_base_container(current_user, distro, docker_cmd, conf)
        # commit the stopped container, remove it, then start new container with the
        # "--userns=keep-id" option for the required container state
        commit_container(current_user, docker_cmd, conf.box_image(False), conf)

    # there is one additional stop/start below because all packages are upgraded by the
    # entrypoint script to pick up any important fixes which can lead to system libraries
    # getting upgraded, so it's best to restart container for those to take effect properly

    # set up the final container with all the required arguments
    print_color(f"Initializing container for '{distro}' using '{config_file}'",
                fg=fgcolor.blue)
    start_container(docker_full_args, current_user, shared_root_dirs, conf)
    print_color("Waiting for the container to initialize (see "
                f"'zbox-logs -f {box_name}' for detailed progress)", fg=fgcolor.blue)
    sys.stdout.flush()
    # wait for container to initialize while printing out its progress from conf.status_file
    wait_for_container(docker_cmd, conf)

    # remove distribution specific scripts and restart container the final time
    print_color(f"Restarting the final container having '{distro}' specific configuration",
                fg=fgcolor.purple)
    for script in conf.distribution_scripts:
        os.unlink(f"{conf.scripts_dir}/{script}")
    restart_container(docker_cmd, conf)
    print_color("Waiting for the container to be ready (see "
                f"'zbox-logs -f {box_name}' for detailed progress)", fg=fgcolor.blue)
    sys.stdout.flush()
    wait_for_container(docker_cmd, conf)


@typechecked
def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="""Create a new zbox container for given Linux distribution and configured
                       with given file in INI format. It allows for set up of various aspects of
                       the zbox including support for X11, Wayland, audio, video acceleration,
                       NVIDIA, dbus among others. It also allows controlling various parameters
                       of the container including directories to be shared, logging etc.""")
    parser.add_argument("-n", "--name", type=str,
                        help="""name of the box; default is <distribution>-<configuration> if
                                not provided (removing the .ini suffix from <configuration>)""")
    parser.add_argument("-d", "--docker-path", type=str,
                        help="path of docker/podman if not in /usr/bin")
    parser.add_argument("distribution", type=str,
                        help="short name of the distribution (should be in supported.list)")
    parser.add_argument("configuration", type=str,
                        help="""the ini configuration file to be used for creating the zbox
                                (can be a relative or absolute path, or be in user or system
                                 configuration directory which are $HOME/.config/zbox and
                                 /etc/zbox respectively)""")
    return parser.parse_args()


@typechecked
def process_args(args: argparse.Namespace) -> (str, str):
    ini_suffix = ".ini"
    if args.name:
        box_name = args.name
    else:
        box_name = os.path.basename(args.configuration)
        if box_name.endswith(ini_suffix):
            box_name = box_name[:-len(ini_suffix)]
        box_name = f"{args.distribution}-{box_name}"

    docker_cmd = get_docker_command(args, "-d")
    return box_name, docker_cmd


@typechecked
def process_sections(config_file: str, distro: str, env: Environ, conf: Configuration,
                     docker_args: list[str]) -> bool:
    now = InitNow()
    # Read the config file, recursively reading the includes if present,
    # then replace the environment variables and the special ${NOW:...} from all values.
    # Skip environment variable substitution for the "configs" section since the values
    # there have to be written as is to 'config.list' file for the container (since the
    #   $HOME variable can be different inside the container).
    env_interpolation = EnvInterpolation(now, ["configs"])
    config = config_reader(config_file, env_interpolation)
    # shared_root is false by default
    shared_root = False
    # hard links are false by default
    config_hardlinks = False
    # finally process all the sections and the keys forming the docker/podman command-line
    for section in config.sections():
        if section == "base":
            shared_root, config_hardlinks = process_base_section(
                config["base"], config_file, env, docker_args)
        elif section == "security":
            process_security_section(config["security"], config_file, docker_args)
        elif section == "mounts":
            process_mounts_section(config["mounts"], docker_args)
        elif section == "env":
            process_env_section(config["env"], docker_args)
        elif section == "configs":
            process_configs_section(config["configs"], config_hardlinks, conf, docker_args)
        elif section == "apps":
            process_apps_section(config["apps"], distro, conf)
        elif section != "appflags" and section != "startup":
            sys.exit(f"Unknown section [{section}] in '{config_file}' or one of its includes")
    return shared_root


@typechecked
def process_base_section(base_section: SectionProxy, config_file: str,
                         env: Environ, args: list[str]) -> (bool, bool):
    # shared root is true by default
    shared_root = True
    # hard links are false by default
    config_hardlinks = False
    for key in base_section:
        if key == "home":
            source_home = base_section[key]
            # create the source directory if it does not exist
            os.makedirs(source_home, exist_ok=True)
            add_mount_option(args, source_home, env.target_home)
        elif key == "shared_root":
            shared_root = base_section.getboolean("shared_root")
        elif key == "config_hardlinks":
            config_hardlinks = base_section.getboolean("config_hardlinks")
        elif key == "x11":
            if base_section.getboolean("x11"):
                enable_x11(args)
        elif key == "wayland":
            if base_section.getboolean("wayland"):
                enable_wayland(args, env)
        elif key == "pulseaudio":
            if base_section.getboolean("pulseaudio"):
                enable_pulse(args, env)
        elif key == "dbus":
            if base_section.getboolean("dbus"):
                enable_dbus(args, base_section.getboolean("dbus_sys", fallback=False))
        elif key == "dri":
            if base_section.getboolean("dri"):
                args.append("--device=/dev/dri")
        elif key == "nvidia":
            if base_section.getboolean("nvidia"):
                args.append("--device=nvidia.com/gpu=all")
        elif key == "shm_size":
            shm_size = base_section["shm_size"]
            if shm_size:
                args.append(f"--shm-size={shm_size}")
        elif key == "pids_limit":
            pids_limit = base_section["pids_limit"]
            if pids_limit:
                args.append(f"--pids-limit={pids_limit}")
        elif key == "log_driver":
            log_driver = base_section["log_driver"]
            if log_driver:
                args.append(f"--log-driver={log_driver}")
        elif key == "log_opts":
            add_multi_opt(args, base_section, "log_opts", "log-opt")
            # create the log directory if required
            log_dirs = [mt.group(1) for mt in
                        (re.match("^--log-opt=path=(.*)/.*$", path) for path in args) if mt]
            for log_dir in log_dirs:
                os.makedirs(log_dir, exist_ok=True)
        elif key != "includes" and key != "dbus_sys":
            sys.exit(f"Unknown key '{key}' in the [base] of {config_file} or its includes")
    return shared_root, config_hardlinks


@typechecked
def add_mount_option(args: list[str], src: str, dest: str, flags: str = "") -> None:
    if flags:
        args.append(f"-v={src}:{dest}:{flags}")
    else:
        args.append(f"-v={src}:{dest}")


@typechecked
def enable_x11(args: list[str]) -> None:
    add_env_option(args, "DISPLAY")
    xsock = "/tmp/.X11-unix"
    if os.access(xsock, os.R_OK):
        add_mount_option(args, xsock, xsock, "ro")
    if xauth := os.environ.get("XAUTHORITY"):
        add_mount_option(args, xauth, xauth, "ro")
        add_env_option(args, "XAUTHORITY", xauth)


@typechecked
def enable_wayland(args: list[str], env: Environ) -> None:
    if wayland_display := os.environ.get("WAYLAND_DISPLAY"):
        add_env_option(args, "WAYLAND_DISPLAY", wayland_display)
        wayland_sock = f"{env.xdg_rt_dir}/{wayland_display}"
        if os.access(wayland_sock, os.W_OK):
            add_mount_option(args, wayland_sock, wayland_sock)


@typechecked
def enable_pulse(args: list[str], env: Environ) -> None:
    cookie = f"{env.home}/.config/pulse/cookie"
    if os.access(cookie, os.R_OK):
        add_mount_option(args, cookie, f"{env.target_home}/.config/pulse/cookie", "ro")
    if env.xdg_rt_dir:
        pulse_native = f"{env.xdg_rt_dir}/pulse/native"
        if os.access(pulse_native, os.W_OK):
            add_mount_option(args, pulse_native, pulse_native)
        for pf in [f for f in os.listdir(env.xdg_rt_dir) if re.match("pipewire-[0-9]+$", f)]:
            pipewire_path = f"{env.xdg_rt_dir}/{pf}"
            if os.access(pipewire_path, os.W_OK):
                add_mount_option(args, pipewire_path, pipewire_path)


@typechecked
def enable_dbus(args: list[str], sys_enable: bool) -> None:
    if dbus_session := os.environ.get("DBUS_SESSION_BUS_ADDRESS"):
        dbus_user = dbus_session[dbus_session.find("=") + 1:]
        if (dbus_opts_idx := dbus_user.find(",")) != -1:
            dbus_user = dbus_user[:dbus_opts_idx]
        add_mount_option(args, dbus_user, dbus_user)
        add_env_option(args, "DBUS_SESSION_BUS_ADDRESS", dbus_session)
    if sys_enable:
        dbus_sys = "/run/dbus/system_bus_socket"
        dbus_sys2 = "/var/run/dbus/system_bus_socket"
        if os.access(dbus_sys, os.W_OK):
            add_mount_option(args, dbus_sys, dbus_sys)
        elif os.access(dbus_sys2, os.W_OK):
            add_mount_option(args, dbus_sys2, dbus_sys)


@typechecked
def add_multi_opt(args: list[str], section: SectionProxy, key: str, opt: str) -> None:
    if opts := section.get(key):
        for opt_val in opts.split(";"):
            args.append(f"--{opt}={opt_val}")


@typechecked
def process_security_section(sec_section: SectionProxy, config_file: str,
                             args: list[str]) -> None:
    sec_options = ["label", "apparmor", "seccomp", "mask", "umask", "proc_opts"]
    single_options = ["seccomp_policy", "ipc", "cgroup_parent", "cgroupns", "cgroups"]
    multi_options = {"caps_add": "cap-add", "caps_drop": "cap-drop", "ulimits": "ulimit",
                     "cgroup_confs": "cgroup-conf", "device_cgroup_rules": "device-cgroup-rule",
                     "secrets": "secret"}
    for key in sec_section:
        if key in sec_options:
            add_sec_option_if_exists(args, sec_section, key.replace("_", "-"))
        elif opt := multi_options.get(key):
            add_multi_opt(args, sec_section, key, opt)
        elif key in single_options:
            add_option_if_exists(args, sec_section, key, key.replace("_", "-"))
        elif key == "no_new_privileges":
            if sec_section.getboolean(key):
                args.append("--security-opt=no-new-privileges")
        else:
            sys.exit(f"Unknown key '{key}' in the [security] of {config_file} or its includes")


@typechecked
def add_sec_option_if_exists(args: list[str], sec_section: SectionProxy, key: str) -> None:
    if val := sec_section[key]:
        args.append(f"--security-opt={key}={val}")


@typechecked
def add_option_if_exists(args: list[str], section: SectionProxy, key: str, opt: str) -> None:
    if val := section[key]:
        args.append(f"--{opt}={val}")


@typechecked
def process_mounts_section(mounts_section: SectionProxy, args: list[str]) -> None:
    for key in mounts_section:
        # keys here are only symbolic names and serve no purpose other than allowing
        # later configuration files to override previous ones
        if val := mounts_section[key]:
            if "=" in val or "," in val:
                args.append(f"--mount={val}")
            else:
                args.append(f"-v={val}")


@typechecked
def process_configs_section(configs_section: SectionProxy, config_hardlinks: bool,
                            conf: Configuration, args: list[str]) -> None:
    # copy or link the mentioned files in [configs] section which can be either files
    # or directories (recursively copy/link in the latter case)
    # this is refreshed on every container start

    # always recreate the directory to pick up any changes
    if os.path.exists(conf.configs_dir):
        shutil.rmtree(conf.configs_dir)
    os.makedirs(conf.configs_dir, exist_ok=True)
    if config_hardlinks:
        print_color("Creating hard links to paths specified in [configs]", fg=fgcolor.blue,
                    end="  ...  ")
    else:
        print_color("Creating a copy of paths specified in [configs]", fg=fgcolor.blue,
                    end="  ...  ")
    # write the links to be created in a file that will be passed to container
    # entrypoint to create symlinks from container user's home to the mounted config files
    with open(conf.config_list, "w", encoding="utf-8") as config_list_fd:
        for key in configs_section:
            val = configs_section[key]
            config_list_fd.write(val)
            config_list_fd.write("\n")
            # perform environment variable substitution now which was skipped earlier
            val = os.path.expandvars(val)
            split_idx = val.find("->")
            if split_idx == -1:
                sys.exit("Incorrect value format in [configs] section for "
                         f"'{key}'. Required: '{{src}} -> {{dest}}'")
            src_path = os.path.realpath(val[:split_idx].strip())
            dest_path = f"{conf.configs_dir}/{val[split_idx + 2:].strip()}"
            if os.access(src_path, os.R_OK):
                os.makedirs(os.path.dirname(dest_path), exist_ok=True)
                if os.path.isdir(src_path):
                    copytree(src_path, dest_path, hardlink=config_hardlinks)
                else:
                    if config_hardlinks:
                        os.link(os.path.realpath(src_path), dest_path, follow_symlinks=True)
                    else:
                        shutil.copy2(src_path, dest_path, follow_symlinks=True)
            else:
                print_color(f"Skipping inaccessible configuration path '{src_path}'",
                            fg=fgcolor.red)
    print_color("DONE", fg=fgcolor.blue)
    # finally mount the configs directory to corresponding directory in the target container
    add_mount_option(args, conf.configs_dir, conf.target_configs_dir, "ro")


@typechecked
def process_apps_section(apps_section: SectionProxy, distro: str, conf: Configuration) -> None:
    # first update the mirrors
    _, _, distro_config = read_distribution_config(distro, conf)
    pkgmgr = distro_config["pkgmgr"]
    install_cmd = pkgmgr["install"]
    cleanup_cmd = pkgmgr["cleanup"]
    if not install_cmd:
        print_color("Skipping app installation since no 'pkgmgr.install' has "
                    "been defined in distro.ini or is empty", fg=fgcolor.lightgray, bg=bgcolor.red)
        return
    # write pkgmgr.conf for entrypoint.sh
    with open(f"{conf.scripts_dir}/pkgmgr.conf", "w", encoding="utf-8") as pkg_fd:
        pkg_fd.write(f"PKGMGR_INSTALL='{install_cmd}'\n")
        pkg_fd.write(f"PKGMGR_CLEANUP='{cleanup_cmd}'\n")
    with open(conf.app_list, "w", encoding="utf-8") as apps_fd:
        extra_args = "extra-args="
        for key in apps_section:
            apps = apps_section[key].split(";")
            args = [a[len(extra_args):] for a in apps if a.startswith(extra_args)]
            args = " ".join(args)
            if args:
                apps = [app for app in apps if not app.startswith(extra_args)]
            apps_fd.write(f"{args} {' '.join(apps)}\n")


# The shutil.copytree(...) method does not work correctly for "symlinks=False" (or at least
#   not like 'cp -rL' or 'cp -rlL') where it does not create the source symlinked file rather
# only the target one in the destination directory.
# This is a simplified version using os.walk(...) that works correctly that always has:
#   a. follow_symlinks=True, and b. ignore_dangling_symlinks=True
@typechecked
def copytree(src: str, dest: str, hardlink: bool = False) -> None:
    for src_dir, _, src_files in os.walk(src, followlinks=True):
        # substitute 'src' prefix with 'dest'
        dest_dir = f"{dest}{src_dir[len(src):]}"
        os.mkdir(dest_dir)
        for src_file in src_files:
            src_path = f"{src_dir}/{src_file}"
            if os.path.exists(src_path):
                if hardlink:
                    os.link(os.path.realpath(src_path), f"{dest_dir}/{src_file}",
                            follow_symlinks=True)
                else:
                    shutil.copy2(src_path, f"{dest_dir}/{src_file}", follow_symlinks=True)


@typechecked
def setup_zbox_scripts(distro: str, conf: Configuration) -> None:
    # first create local mount directory having entrypoint and other scripts
    if os.path.exists(conf.scripts_dir):
        shutil.rmtree(conf.scripts_dir)
    os.makedirs(conf.scripts_dir, exist_ok=True)
    # copy the common scripts
    for script in [conf.entrypoint_base, conf.entrypoint_cp, conf.entrypoint,
                   "entrypoint-common.sh", "prime-run"]:
        path = conf.get_config_file(f"resources/{script}")
        shutil.copy2(path, f"{conf.scripts_dir}/{script}", follow_symlinks=True)
    # also copy distribution specific scripts
    for script in conf.distribution_scripts:
        path = conf.get_config_file(f"{distro}/{script}")
        shutil.copy2(path, f"{conf.scripts_dir}/{script}", follow_symlinks=True)


@typechecked
def read_distribution_config(distro: str, conf: Configuration) -> (str, str, ConfigParser):
    distro_config = config_reader(conf.get_config_file(f"{distro}/distro.ini"), None)
    distro_base_section = distro_config["base"]
    image_name = distro_base_section["image"]  # should always exist
    shared_root_dirs = distro_base_section["shared_root_dirs"]  # should always exist
    return image_name, shared_root_dirs, distro_config


@typechecked
def run_base_container(current_user: str, distro: str, docker_cmd: str,
                       conf: Configuration) -> str:
    # determine the base image name
    image_name, shared_root_dirs, _ = read_distribution_config(distro, conf)
    # refresh the image locally first to decrease update size later
    print_color(f"Refreshing local copy of the base image '{image_name}'", fg=fgcolor.purple)
    pull_result = subprocess.run([docker_cmd, "pull", image_name])
    if pull_result.returncode != 0:
        print_color("FAILED -- see the output above for details", fg=fgcolor.red)
        print_color("Continuing with the local copy of the image", fg=fgcolor.purple)
    # get current user and group details to pass to the entrypoint script
    user_entry = pwd.getpwnam(current_user)
    group_entry = grp.getgrgid(user_entry.pw_gid)
    print_color(f"Creating container specific image having sudo user '{current_user}'",
                fg=fgcolor.purple)
    docker_run = [docker_cmd, "run", "-it", "-e=XDG_RUNTIME_DIR", f"--name={conf.box_name}",
                  f"-v={conf.scripts_dir}:{conf.target_scripts_dir}:ro",
                  f"--label={ZboxLabel.CONTAINER_BASE}",
                  f"--entrypoint={conf.target_scripts_dir}/{conf.entrypoint_base}",
                  image_name, "-u", current_user, "-U", str(user_entry.pw_uid),
                  "-n", user_entry.pw_gecos, "-g", group_entry.gr_name,
                  "-G", str(group_entry.gr_gid)]
    if conf.localtime:
        docker_run.append("-l")
        docker_run.append(conf.localtime)
    if conf.timezone:
        docker_run.append("-z")
        docker_run.append(conf.timezone)
    init_result = subprocess.run(docker_run)
    if init_result.returncode != 0:
        print_color("FAILED -- see the output above for details", fg=fgcolor.red)
        sys.exit(1)
    # return value is the semicolon separated list of directories to be mounted in the
    # shared location for the final containers
    return shared_root_dirs


@typechecked
def run_shared_copy_container(distro: str, docker_cmd: str, image_name: str,
                              shared_root_dirs: str, conf: Configuration) -> None:
    root_host = conf.shared_root_host_dir
    # if shared root copy exists locally, then prompt user to delete it or else exit
    if os.path.exists(root_host):
        input_msg = f"""
            The shared root directory for '{distro}' already exists in:
                {root_host}
            However, the corresponding zbox container image for '{distro}' does not exist.
            This can happen if an old copy of shared root directory is lying around and
            is usually safe to remove, but you should be sure that no other zbox is running
            for '{distro}' with 'shared_root' configuration that is using that directory.
            Should the root directory be removed (y/N): """
        response = input(dedent(input_msg))
        if response.lower() == "y":
            try:
                shutil.rmtree(root_host)
            except OSError:
                # try with sudo
                sudo_rm = subprocess.run(["sudo", "/bin/rm", "-rf", root_host])
                if sudo_rm.returncode != 0:
                    print_color("FAILED to delete directory -- see the output above for details",
                                fg=fgcolor.red)
                    sys.exit(1)
        else:
            print_color(f"Aborting creation of zbox container '{conf.box_name}'", fg=fgcolor.red)
            # remove the temporary image before exit
            remove_image(docker_cmd, image_name)
            sys.exit(1)
    os.makedirs(root_host)
    # the entrypoint-cp.sh script requires two arguments: first is the semicolon separated
    # list of directories to be copied, and second the target directory
    init_result = subprocess.run([docker_cmd, "run", "-it", f"--name={conf.box_name}",
                                  f"-v={conf.scripts_dir}:{conf.target_scripts_dir}:ro",
                                  f"-v={root_host}:{conf.shared_root_mount_dir}",
                                  f"--label={ZboxLabel.CONTAINER_COPY}",
                                  "--userns=keep-id", "--user=0",
                                  f"--entrypoint={conf.target_scripts_dir}/{conf.entrypoint_cp}",
                                  image_name, shared_root_dirs, conf.shared_root_mount_dir])
    if init_result.returncode != 0:
        print_color("FAILED -- see the output above for details", fg=fgcolor.red)
        sys.exit(1)


@typechecked
def print_subprocess_output(result: subprocess.CompletedProcess) -> None:
    print_color(result.stdout.decode("utf-8"))
    print_color(result.stderr.decode("utf-8"), fg=fgcolor.orange)


@typechecked
def commit_container(current_user: str, docker_cmd: str, box_image: str,
                     conf: Configuration) -> None:
    commit_result = subprocess.run([docker_cmd, "commit", f"-c=USER={current_user}",
                                    f"-c=WORKDIR=/home/{current_user}", conf.box_name,
                                    box_image], capture_output=True)
    if commit_result.returncode != 0:
        print_subprocess_output(commit_result)
        print_color("FAILED in container commit -- see the output above for details",
                    fg=fgcolor.red)
        sys.exit(1)

    remove_result = subprocess.run([docker_cmd, "container", "rm", conf.box_name])
    if remove_result.returncode != 0:
        print_color("FAILED in container rm -- see the output above for details",
                    fg=fgcolor.red)
        sys.exit(1)


@typechecked
def remove_image(docker_cmd: str, box_image: str) -> None:
    rm_result = subprocess.run([docker_cmd, "image", "rm", box_image], capture_output=True)
    if rm_result.returncode != 0:
        print_subprocess_output(rm_result)
        print_color("FAILED in image remove -- see the output above for details",
                    fg=fgcolor.red)


@typechecked
def start_container(docker_full_cmd: list[str], current_user: str, shared_root_dirs: str,
                    conf: Configuration) -> None:
    add_mount_option(docker_full_cmd, conf.scripts_dir, conf.target_scripts_dir, "ro")
    # touch the status file and mount it
    status_path = Path(conf.status_file)
    status_path.unlink(missing_ok=True)
    status_path.touch(mode=0o600, exist_ok=False)
    add_mount_option(docker_full_cmd, conf.status_file, conf.status_target_file)

    for shared_dir in shared_root_dirs.split(";"):
        add_mount_option(docker_full_cmd, f"{conf.shared_root_host_dir}{shared_dir}", shared_dir)
    for lang_var in ["LANG", "LANGUAGE"]:
        docker_full_cmd.append(f"-e={lang_var}")
    docker_full_cmd.append("-e=XDG_RUNTIME_DIR")
    docker_full_cmd.append(f"--label={ZboxLabel.CONTAINER_PRIMARY}")
    docker_full_cmd.append(f"--entrypoint={conf.target_scripts_dir}/{conf.entrypoint}")
    docker_full_cmd.append("--userns=keep-id")
    # bubblewrap and thereby programs like steam do not work without this
    # (https://github.com/containers/bubblewrap/issues/380#issuecomment-648169485)
    user_entry = pwd.getpwnam(current_user)
    docker_full_cmd.append(f"--user={user_entry.pw_uid}:{user_entry.pw_gid}")
    docker_full_cmd.append(conf.box_image(bool(shared_root_dirs)))
    if os.access(conf.config_list, os.R_OK):
        docker_full_cmd.extend(["-c", f"{conf.target_scripts_dir}/config.list",
                                "-d", conf.target_configs_dir])
    if os.access(conf.app_list, os.R_OK):
        docker_full_cmd.append("-a")
        docker_full_cmd.append(f"{conf.target_scripts_dir}/app.list")

    docker_full_cmd.append(conf.box_name)
    launch_result = subprocess.run(docker_full_cmd)
    if launch_result.returncode != 0:
        print_color("FAILED to launch container -- see the output above and check "
                    f"'zbox-logs {conf.box_name}' for details", fg=fgcolor.red)
        sys.exit(1)


@typechecked
def wait_for_container(docker_cmd: str, conf: Configuration) -> None:
    box_name = conf.box_name
    max_wait_secs = 600
    with open(conf.status_file, "r", encoding="utf-8") as status_fd:
        for secs in range(max_wait_secs):
            # check the container status first
            if check_running_zbox(docker_cmd, box_name):
                while line := status_fd.readline():
                    if line == "started\n":
                        # clear the status file and return
                        truncate_file(conf.status_file)
                        return
                    print(line, end="")  # line already includes the terminating newline
            else:
                # check if container has explicitly stopped for restart later
                while line := status_fd.readline():
                    print(line, end="")  # line already includes the terminating newline
                    if line == "stopped\n":
                        # clear the status file and return
                        truncate_file(conf.status_file)
                        return
                print_color("FAILED waiting for container to be ready -- check "
                            f"'zbox-logs {box_name}' for details", fg=fgcolor.red)
                sys.exit(1)
            # using simple poll per second rather than inotify or similar because the
            # initialization will take a good amount of time and second granularity is enough
            time.sleep(1)
    # reading did not end after max_wait_secs
    print_color(f"TIMED OUT waiting for ready container after {max_wait_secs}secs -- check "
                f"'zbox-logs -f {box_name}' for details", fg=fgcolor.red)
    sys.exit(1)


@typechecked
def truncate_file(f: str) -> None:
    with open(f, "a") as fd:
        fd.truncate(0)


@typechecked
def restart_container(docker_cmd: str, conf: Configuration) -> None:
    launch_result = subprocess.run([docker_cmd, "container", "start", conf.box_name])
    if launch_result.returncode != 0:
        print_color("FAILED to restart container -- see the output above and check "
                    f"'zbox-logs {conf.box_name}' for details", fg=fgcolor.red)
        sys.exit(1)


main()
